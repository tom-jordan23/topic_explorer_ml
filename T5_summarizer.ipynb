{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize data with T5\n",
    "\n",
    "Experimenting with BART sumamrization models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sentencepiece\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config variables\n",
    "\n",
    "summary_file = \"summary_orig.xlsx\"\n",
    "summarization_model = \"google/flan-t5-base\"\n",
    "question_answer_model = \"deepset/roberta-base-squad2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the excel data into a pandas dataframe\n",
    "directory_path = os.getcwd()\n",
    "summary_file = os.path.join(directory_path, summary_file)\n",
    "print(summary_file)\n",
    "df = pd.read_excel(summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the summarization pipeline and loop through the dataframe to summarize the data \n",
    "# in the source_original_text column and add the summary to the dataframe in a column named source_summary\n",
    "\n",
    "summarizer = T5ForConditionalGeneration.from_pretrained(summarization_model)\n",
    "tokenizer = T5Tokenizer.from_pretrained(summarization_model)\n",
    "\n",
    "scaling_factor = 0.5 #how much we want to scale the summary length\n",
    "\n",
    "df_results = pd.DataFrame(columns=[\"source_text\", \"summary_text\", \"source_text_tokens\", \"summary_text_tokens\", \"max_length\", \"min_length\", \"model used\"])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    source_text = row[\"source_original_text\"]\n",
    "    print(\"Original text: \", source_text)\n",
    "\n",
    "    # tokenize the input text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + source_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    input_length = len(inputs[0])\n",
    "    print(\"Input Token length: \", input_length)\n",
    "\n",
    "    # scale the summary length based on the input length\n",
    "    max_length = int(input_length * scaling_factor)\n",
    "    min_length = 50\n",
    "    if max_length < 50:\n",
    "        min_length = int(max_length * 0.5)\n",
    "\n",
    "    summary_ids = summarizer.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    print(\"Summary Token length: \", len(summary_ids[0]))\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    print(\"Summary text: \", summary)\n",
    "    df_results.at[index, \"source_text\"] = source_text\n",
    "    df_results.at[index, \"summary_text\"] = summary\n",
    "    df_results.at[index, \"source_text_tokens\"] = input_length\n",
    "    df_results.at[index, \"summary_text_tokens\"] = len(summary_ids[0])\n",
    "    df_results.at[index, \"max_length\"] = max_length\n",
    "    df_results.at[index, \"min_length\"] = min_length\n",
    "    df_results.at[index, \"model used\"] = summarization_model\n",
    "\n",
    "# now write an excel file with the summarized data\n",
    "df_results.to_excel(\"summarized_data_flan_T5_base.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
