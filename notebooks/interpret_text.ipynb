{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b57c0df-aad2-417d-a0a9-2667509f213b",
   "metadata": {},
   "source": [
    "Once the content has been downloaded and split into paragraphs, perform preprocessing\n",
    "\n",
    "TODO\n",
    "\n",
    "Parentheticals structured like this need to be addressed\n",
    "35 suspected measles cases in Idleb (16) Aleppo (5) Daraa (4) Rural Damascus (3) Homs (2) Hama (2) Deir-ez-Zor (2) AlHasakeh (1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd2a997-7135-4df9-9fbd-cfcc751c8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import re\n",
    "import importlib\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import spacy\n",
    "from textacy import preprocessing\n",
    "\n",
    "import sys\n",
    "sys.path.append('utilities')\n",
    "import basic_utilities as utils\n",
    "import preprocessing_utilities as preputils\n",
    "import nlp_utilities as nlputils\n",
    "\n",
    "\n",
    "import spacy\n",
    "from textacy import extract\n",
    "from spacy import displacy\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522b2cc0-a44e-47b8-871b-3be25c7b0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"stored_data\\\\rw_disaster_situation_reports_8a4af19ed04345f2b41d8de4adb98d4e.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1c18cf-0e8e-48bd-a152-864a20015d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097e416-73cb-47fd-9776-b9811997c34c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e04559d7-cec7-43e1-914c-2c4f3e42e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(preputils)\n",
    "df['preprocessed_text'] = df['text'].apply(preputils.simple_string_preprocessing)\n",
    "df['preprocessed_text'] = df['preprocessed_text'].apply(preputils.numeric_string_preprocessing)\n",
    "\n",
    "#if the field isn't text, drop the record\n",
    "def clean_main_text_field(text):\n",
    "    if isinstance(text, str) == False:\n",
    "        return None\n",
    "    else:\n",
    "        return text\n",
    "        \n",
    "df['preprocessed_text'] = df['preprocessed_text'].apply(clean_main_text_field)\n",
    "df = df[df['preprocessed_text'].isna() == False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a4d458-8d87-47ff-b2a5-97f8c28a91fd",
   "metadata": {},
   "source": [
    "## Load Other Controller Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003b7c75-b6fd-46af-8d70-9e9716404859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load indicators\n",
    "indicator_file = 'stored_data\\\\word_indicators.xlsx'\n",
    "df_ind = pd.read_excel(indicator_file)\n",
    "df_ind.set_index('word', inplace=True)\n",
    "indicators = {}\n",
    "for c in df_ind.columns:\n",
    "    indicators[c] = df_ind[df_ind[c].isna() == False].index.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7845ff9-24f8-48eb-b208-1413413936cb",
   "metadata": {},
   "source": [
    "## NLP Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9e88a9-577d-4d40-8ef9-8f385ec789dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP the text, break sentences out into their own row\n",
    "\n",
    "def spacify_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return nlp(text)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def expand_sentences(df):\n",
    "    # Function to increment by one for each idx_parad\n",
    "    def generate_sent_id(group, new_column_name='idx_sent'):\n",
    "        group[new_column_name] = range(0, len(group))\n",
    "        return group\n",
    "    \n",
    "    df['spacy_doc'] = df['preprocessed_text'].apply(lambda text: spacify_text(text))\n",
    "\n",
    "    # inefficient to write out to text, just to spacify again...\n",
    "    df['spacy_doc'] = df['spacy_doc'].apply(lambda x: [sent.text for sent in x.sents])\n",
    "    df = df.explode('spacy_doc')\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df = df.groupby(['doc_id','idx_para']).apply(generate_sent_id).reset_index(drop=True)\n",
    "\n",
    "    # inefficient to write out to text, just to spacify again...\n",
    "    df['spacy_doc'] = df['spacy_doc'].apply(lambda text: spacify_text(text))\n",
    "    df['record_id'] = df['doc_id'].astype(str) + \"_\" +  df['idx_para'].apply(lambda x: f\"{x:04d}\") + \"_\" + df['idx_sent'].apply(lambda x: f\"{x:04d}\")\n",
    "\n",
    "    #reorg column headers\n",
    "    df = df[['record_type','source_url','glide_id','doc_id','idx_para','idx_sent','record_id','source_level_country','source_title','source_desc','source_original_text','reference_url','authoring_org','reported_date','preprocessed_text','spacy_doc']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = expand_sentences(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9341ea9-86e7-483e-9567-0a201dbfa2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['spacy_doc'].isna() == False].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1a11d2-3d7c-4cb0-8f45-e4e81fc2f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_future_tense_verb(doc):\n",
    "    def is_future_tense(token):\n",
    "        #Check if a token is indicative of future tense.\n",
    "        return (\n",
    "            token.tag_ == \"MD\" and token.text.lower() == \"will\"\n",
    "            or (token.dep_ == \"aux\" and token.head.lemma_ == \"will\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf2ef77-b981-455d-935e-07f44ae11932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lower_lemmas'] = df['spacy_doc'].apply(lambda x: [w.lemma_.lower() for w in x])\n",
    " \n",
    "\n",
    "df['locations'] = df['spacy_doc'].apply(lambda doc: [e.text for e in doc.ents if e.label_ == 'GPE'])\n",
    "df['dates'] = df['spacy_doc'].apply(lambda doc: [e.text for e in doc.ents if e.label_ == 'DATE'])\n",
    "df['svot'] = df['spacy_doc'].apply(lambda doc: list(extract.subject_verb_object_triples(doc)))\n",
    "df['future_verbs'] = df['spacy_doc'].apply(get_future_tense_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "382e0d17-d712-4cac-9b04-2f0e371ba782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_add_indicator(df, indicators):\n",
    "        \n",
    "    ind_counter = []\n",
    "    for ind in indicators:\n",
    "  \n",
    "        df[ind] = df['lower_lemmas'].apply(lambda x: 1 if len([w for w in x if w in indicators[ind]])>0 else 0)\n",
    "        ind_counter.append(ind)\n",
    "        #print(ind_counter)\n",
    "    df['i_count'] = df[ind_counter].sum(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = find_and_add_indicator(df, indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3d15899-ec3e-4880-a383-6ab6a5652ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cardinalities(doc):\n",
    "    if doc is None:\n",
    "        return None\n",
    "\n",
    "    cardinalities = []\n",
    "    for e in doc.ents:\n",
    "        if e.label_ == \"CARDINAL\": # it's a cardinal, find out what it's related to\n",
    "            for t in e:\n",
    "                if t.pos_ == 'NUM':\n",
    "                    numeric_token = t\n",
    "                    object = t.head\n",
    "                    cardinalities.append([numeric_token, object, object.head])\n",
    "    if len(cardinalities) > 0:\n",
    "        return cardinalities\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#get_cardinalities(doc)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "421cd3f9-ce12-4b2d-bde3-af21088c1821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cardinalities'] = df['spacy_doc'].apply(get_cardinalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "46406fa3-91a8-4768-9ecd-3f141ff3180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_exploder(df, explode_field):\n",
    "    tmp_df = df.explode(explode_field)\n",
    "    tmp_df.reset_index(drop=True, inplace=True)\n",
    "    return tmp_df\n",
    "\n",
    "\n",
    "df_cardinalities = df[['record_id','spacy_doc','cardinalities']].copy()\n",
    "df_cardinalities = df_exploder(df_cardinalities, 'cardinalities')\n",
    "df_cardinalities = df_cardinalities[df_cardinalities['cardinalities'].isna() == False].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e9d4aac6-b9ec-4d5a-8b4a-7de1a88c0afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cardinalities[['one','two','three']] = df_cardinalities['cardinalities'].apply(pd.Series)\n",
    "df_cardinalities['lower_lemma'] = df_cardinalities['three'].apply(lambda x: x.lemma_.lower())\n",
    "#had to split out the function to make the ll a list to make it work...\n",
    "df_cardinalities['lower_lemmas'] = df_cardinalities['lower_lemma'].apply(lambda x: [x]) \n",
    "df_cardinalities = find_and_add_indicator(df_cardinalities, indicators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0247527-acf8-4df1-b901-605a6eaf4778",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "04788269-c31b-48c4-998d-c3f82e21f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"c://temp//processed_disaster_summaries.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
