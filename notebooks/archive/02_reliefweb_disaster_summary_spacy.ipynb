{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f8e5b3-6bb9-4eaa-a618-0c9baa633823",
   "metadata": {},
   "source": [
    "# Begin the actual NLP work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "ec487232-ba50-42d3-9a83-af5151ea68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from textacy import extract\n",
    "\n",
    "from collections import defaultdict \n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "5b469fda-126a-4179-8ca8-49251c72f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_summary_preprocessed_file = \"D://projects//_external_files//surveyor//rw_disaster_preprocessed//disaster_summaries_preprocessed_9fcc0753cbbf4fb7a37ea5a15f872a11.xlsx\"\n",
    "pcode_file = \"D://projects//_external_files//cod_files//combined_locations//locations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "b4ce36a7-9ecd-48f4-ada5-88df466111c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2023, tm_mon=12, tm_mday=10, tm_hour=16, tm_min=23, tm_sec=9, tm_wday=6, tm_yday=344, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(time.localtime())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416faa00-a5f3-4399-80de-554744d96f8f",
   "metadata": {},
   "source": [
    "## Load Location Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "56d721c8-d876-4a2a-9ebd-3f5558fbbc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = pd.read_csv(pcode_file)\n",
    "\n",
    "def get_pcode_from_location(loc, country_prefix='XX', lang_code='all'):\n",
    "\n",
    "    if country_prefix != 'XX': #if the country prefix is set, limit search to that\n",
    "        df_loc = df_location[df_location['pcode_prefix'] == country_prefix]\n",
    "    else:\n",
    "        df_loc = df_location\n",
    "\n",
    "    if lang_code != 'all': #secondary filter - especially important to remove dupes with diff langs share the same script\n",
    "        df_loc = df_loc[df_loc['lang_code'] == lang_code]\n",
    "        \n",
    "    matches = df_loc['pcode'][df_loc['location_name'].str.lower() == loc.lower()].tolist()\n",
    "\n",
    "    #if the match fails, try again on the normalized name\n",
    "    if len(matches) == 0:\n",
    "        #remove common variations in names that can cause misses\n",
    "        n_loc = re.sub(r'[^a-zA-Z]', '', loc)\n",
    "\n",
    "        #this will cause problems for non-English.. so if then len is 0, exit\n",
    "        if len(n_loc) == 0:\n",
    "            return []\n",
    "            \n",
    "        matches = df_loc['pcode'][df_loc['location_normalized'].str.lower() == n_loc.lower()].tolist()\n",
    "        \n",
    "\n",
    "    #now check results\n",
    "    if len(matches) > 1:\n",
    "        #print(f\"more than 1 matches... likely due to different granularity of entities with the same name (ie. Herat City in Herat Province) {matches}\")\n",
    "        #print(f\"returning the lowest granularity match. {min(matches, key=len)}\")\n",
    "        #print(\"if the pcodes are all the same granularity.... you get the first element.\")\n",
    "        return min(matches, key=len)\n",
    "            \n",
    "        return matches[0]\n",
    "    elif len(matches) == 1:\n",
    "        return matches[0]\n",
    "\n",
    "    else:\n",
    "        #couldn't find a match, do a fuzzy search\n",
    "        compare_list = list(set(df_loc['location_name'].tolist()))\n",
    "        possible_matches=[]\n",
    "        for i in compare_list:\n",
    "            if fuzz.ratio(loc,i) > 70:\n",
    "                possible_matches.append(i)\n",
    "                print (f\"No exact match to '{loc}'. see if these alternative spellings are correct: {possible_matches}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "assert get_pcode_from_location('istanbul') == 'TUR034'\n",
    "\n",
    "def get_adm_lvl_from_pcode(pcode):\n",
    "    return list(set(df_location['adm_lvl'][df_location['pcode'] == pcode].tolist()))\n",
    "    \n",
    "def get_name_in_lang(pcode, lang='en'):\n",
    "    return list(set(df_location['location_name'][(df_location['pcode'] == pcode) & (df_location['lang_code'] == lang)].tolist()))\n",
    "\n",
    "def get_descendents_of(pcode, lang='en', include_self=True):\n",
    "    if include_self==True:\n",
    "        return df_location[df_location['pcode'].str.contains(pcode) & (df_location['lang_code'] == lang)]\n",
    "    else:\n",
    "        return df_location[df_location['pcode'].str.contains(pcode) & (df_location['lang_code'] == lang)\\\n",
    "        & (df_location['pcode'] != pcode)]\n",
    "\n",
    "def get_admin_chain(pcode, lang='en'):\n",
    "    split_pcode = df_location['split_pcode'][df_location['pcode'] == pcode].tolist()[0]\n",
    "    levels = split_pcode.split(\".\")\n",
    "    pc =''\n",
    "    admin_chain = []\n",
    "    #rebuild the pcode one level at a time\n",
    "    for i in levels:\n",
    "        pc = pc + i\n",
    "        admin_chain.append(df_location['location_name'][(df_location['pcode'] == pc) & (df_location['lang_code'] == lang)].tolist()[0])\n",
    "\n",
    "    return admin_chain\n",
    "\n",
    "def get_all_locations(lang_code='all'):\n",
    "\n",
    "    #return all unique location names\n",
    "    if lang_code == 'all':\n",
    "        return list(set(df_location['location_name'].to_list()))\n",
    "    else:\n",
    "        return list(set(df_location['location_name'][df_location['lang_code'] == lang_code].to_list()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "9f1aa28e-da87-4ebc-9fd4-6d8ac7c43fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create patterns and add to the entity ruler to better find locations\n",
    "\n",
    "all_locs = get_all_locations(lang_code='en')\n",
    "gpes = []\n",
    "\n",
    "STOP_LOCS = ['of','can']\n",
    "all_locs = [e for e in all_locs if e.lower() not in STOP_LOCS]\n",
    "\n",
    "# create pattern rules for locations based on the COD files\n",
    "for l in all_locs:\n",
    "    token_sequence=[]\n",
    "    for token in l.split('\\s+'):\n",
    "        token_sequence.append({\"LOWER\":token.lower()})\n",
    "    x = {'label':'COD_GPE', 'pattern': token_sequence, 'id':get_pcode_from_location(l, lang_code='en')[0]}\n",
    "    gpes.append(x)\n",
    "    #print(get_pcode_from_location(l, lang_code='en'))\n",
    "\n",
    "ruler = nlp.add_pipe('entity_ruler', before='ner')\n",
    "ruler.add_patterns(gpes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a95e9-7e7f-4d92-ac1c-9e46b2d645f7",
   "metadata": {},
   "source": [
    "## Build DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "8a43d860-516f-49d6-a9bf-8144b7255138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_excel(disaster_summary_preprocessed_file)\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "b1def37c-68a5-42d3-86ed-0eef298de998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_to_sentence_level(doc):\n",
    "    sentences = []\n",
    "    #print()\n",
    "    #print(doc)\n",
    "    for sent in doc.sents:\n",
    "        #print(sent)\n",
    "        #create new doc objects for each sentence and append to a list\n",
    "        doc_from_span = spacy.tokens.Doc(doc.vocab, words=[token.text for token in sent])\n",
    "        sentences.append(doc_from_span)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def expand_to_sentence_level(doc):\n",
    "    sentences = []\n",
    "    for sent in doc.sents:\n",
    "        sent_text = sent.text\n",
    "        if len(sent_text) > 20:\n",
    "            sentences.append(nlp(sent_text)) # horrendously inefficient but...\n",
    "    if len(sentences) == 0:\n",
    "        sentences.append(nlp(\"No content to return.\"))\n",
    "    return sentences\n",
    "\n",
    "# Function to increment by one for each idx_parad\n",
    "def generate_sent_id(group, new_column_name='idx_sent'):\n",
    "    group[new_column_name] = range(0, len(group))\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "3accd8c6-3e9e-41e7-ac23-f1c021f0a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['record_type', 'status', 'source_url', 'glide_id', 'idx_para',\n",
       "       'source_level_country', 'source_title', 'source_desc',\n",
       "       'source_original_text', 'reference_url', 'text', 'authoring_org',\n",
       "       'reported_date', 'references', 'reference_auth_org',\n",
       "       'reference_date_str', 'reference_date_iso', 'para_id',\n",
       "       'non_parenthetical_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "85068c8b-06cf-4e8b-8fd2-261758037193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#focus on ongoing for nowd\n",
    "df_sents = df[df['status'] == 'ongoing'].copy()\n",
    "df_sents['spacy_para_no_paren'] = df_sents['non_parenthetical_text'].apply(lambda x: nlp(x))\n",
    "df_sents['spacy_sent_no_paren'] = df_sents['spacy_para_no_paren'].apply(expand_to_sentence_level)\n",
    "df_sents = df_sents.explode('spacy_sent_no_paren')\n",
    "\n",
    "# Apply the function to the DataFrame using groupby on 'idx_para'\n",
    "df_sents = df_sents.groupby(['para_id','idx_para']).apply(generate_sent_id).reset_index(drop=True)\n",
    "df_sents = df_sents[['glide_id','reference_auth_org','para_id','idx_para','idx_sent','source_level_country','source_original_text','spacy_sent_no_paren','reference_date_iso']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e5fa5-151a-476a-a608-4d1dd304636d",
   "metadata": {},
   "source": [
    "## Data Structure Completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "7fe7f050-bffc-4055-9e91-2ce3a09f9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword_indicators\n",
    "indicators = {\n",
    "    'i_people' : ['people','person','child','man','woman','civilian','colleague','fatality','individual']\n",
    "    ,'i_killed' : ['dead','fatal','die','kill','deceased','fatality','fatality','death','deaths'] #think about how to incorporate 2 co-existing terms \"648 people who lost their lives\"\n",
    "    ,'i_injured' : ['injure','wound','wounded','injured']\n",
    "    ,'i_damage' : ['damage','destroy','collapse']\n",
    "    ,'i_health_infrastructure' : ['hospital','surgery']\n",
    "    ,'i_education_infrastructure' : ['school','university']\n",
    "    ,'i_cash_xfer' : ['xx']\n",
    "    ,'i_wash' : ['sanitation','water','sewer','drain','drainage']\n",
    "    ,'i_shelter' : ['shelter','tent','camp','blanket']\n",
    "    ,'i_food' : ['food','cook','stove','feed','feed','nutrient','meal']\n",
    "    ,'i_health' : ['health','medical','medicine']\n",
    "    ,'i_gender_vuln' : ['dignity','gender','pregnant','lactate','lactating']\n",
    "    ,'i_protection' : ['trauma','mental']\n",
    "    ,'i_response_capacity' : ['personnel']\n",
    "    ,'i_other_infrastructure' : ['communicate','radio','internet','telecommunication','electric','line']\n",
    "    ,'i_money' : ['grant','loan','finance','appeal','chf','fund']\n",
    "    ,'i_other' : ['biometric']\n",
    "    ,'i_problem' : ['challenge']\n",
    "    ,'i_demand_side' : ['need','demand','gap','priority', 'receive'] # note receive implies both supply and demand\n",
    "    ,'i_supply_side' : ['response','contribute','provide','source','address','deploy','receive'] # note receive implies both supply and demand\n",
    "\n",
    "    ,'i_assessments' : ['assess','assessment']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "8e246a87-b286-4858-80e4-8d32e612a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_int(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "        \n",
    "    text = re.sub(',', '', text.text)\n",
    "    try:\n",
    "        return int(text)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_numeric_value(doc, indicator):\n",
    "    #indicator needs to be either i_killed, or i_injured\n",
    "    \n",
    "\n",
    "    key_values = []\n",
    "    just_count = []\n",
    "    \n",
    "    def check_flags(lst):\n",
    "        for l in lst:\n",
    "            if l == -1:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def reset_indicators():\n",
    "        return -1, -1, -1\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        noun, attribute, count = reset_indicators()\n",
    "    \n",
    "        \n",
    "                \n",
    "        for t in sent:\n",
    "            #print(t)\n",
    "            if (t.pos_ == 'NUM') & (t.ent_type_ not in ['DATE','TIME']):\n",
    "                count = t\n",
    "    \n",
    "            if t.lemma_ in indicators[indicator]:\n",
    "                attribute = t\n",
    "            if check_flags([attribute,count]):\n",
    "    \n",
    "                noun_att_cnt = (attribute,count)\n",
    "                key_values.append(noun_att_cnt)\n",
    "                just_count.append(count)\n",
    "    \n",
    "                noun, attribute, count = reset_indicators()\n",
    "\n",
    "    #if more than 1 figure is returned, typically those will be\n",
    "    #contextualizing numbers, just return the first\n",
    "    if len(just_count) > 0:\n",
    "        #return [just_count,key_values]\n",
    "        return just_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "c7f08412-eddc-4846-b82f-e1bc3dbb9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents['num_killed'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_numeric_value(x, 'i_killed'))\n",
    "df_sents['num_injured'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_numeric_value(x, 'i_injured'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295b1a4-a431-4889-a23d-90709048d440",
   "metadata": {},
   "source": [
    "## get Location Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "cbf2859e-6344-4450-98d0-7f7c534f597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gpe_entities(doc, adm_lvl='0'):\n",
    "    entities = []\n",
    "    admins = []\n",
    "    #COD_GPE\n",
    "    ents = list(extract.entities(doc))\n",
    "    if len(ents) < 1:\n",
    "        return None\n",
    "    else:\n",
    "        for e in ents:\n",
    "            if e.label_ == 'COD_GPE':\n",
    "                entities.append(e)\n",
    "\n",
    "        for e in entities:\n",
    "            pcode = get_pcode_from_location(e.text)\n",
    "            if (pcode is not None):\n",
    "                if (len(pcode) != 0):\n",
    "                    #print(pcode)\n",
    "                    admins.append(get_admin_chain(pcode)[adm_lvl])\n",
    "\n",
    "    admins = list(set(admins))\n",
    "    if len(admins) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return admins[0] \n",
    "\n",
    "df_sents['identified_country'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_gpe_entities(x, adm_lvl=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "22f8885b-e1c1-45da-af97-efbc32255734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents['identified_country'] = df_sents['identified_country'].fillna(df_sents['source_level_country'])\n",
    "df_sents['num_killed_int'] = df_sents['num_killed'].apply(translate_to_int)\n",
    "df_sents['num_injured_int'] = df_sents['num_injured'].apply(translate_to_int)\n",
    "#DataFrame.astype(dtype, copy=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "bcaaf384-4004-4a06-a6af-016c9fe27c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents.to_excel(\"c://temp//ongoing.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4bda2294-3acf-4967-ab8f-45423523ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents[df_sents['glide_id'] == 'EQ-2023-000015-TUR'].to_excel(\"c://temp//foo2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "949b58dc-a256-4cda-a453-5c7275273d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sents.to_csv(\"c://temp//foo.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "60e2f2b6-05f4-4e7c-b5fe-841943c3efde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glide_id</th>\n",
       "      <th>reference_auth_org</th>\n",
       "      <th>para_id</th>\n",
       "      <th>idx_para</th>\n",
       "      <th>idx_sent</th>\n",
       "      <th>source_level_country</th>\n",
       "      <th>source_original_text</th>\n",
       "      <th>spacy_sent_no_paren</th>\n",
       "      <th>reference_date_iso</th>\n",
       "      <th>num_killed</th>\n",
       "      <th>num_injured</th>\n",
       "      <th>identified_country</th>\n",
       "      <th>num_killed_int</th>\n",
       "      <th>num_injured_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>On 6 February, a 7.7 magnitude earthquake stru...</td>\n",
       "      <td>(On, 6, February, ,, a, 7.7, magnitude, earthq...</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>On 6 February, a 7.7 magnitude earthquake stru...</td>\n",
       "      <td>(This, is, Türkiye, 's, most, powerful, earthq...</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>On 6 February, a 7.7 magnitude earthquake stru...</td>\n",
       "      <td>(The, Government, of, Türkiye, has, since, iss...</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>On 6 February, a 7.7 magnitude earthquake stru...</td>\n",
       "      <td>(The, earthquake, also, heavily, impacted, nor...</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Syrian Arab Republic]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>On 6 February, a 7.7 magnitude earthquake stru...</td>\n",
       "      <td>(The, humanitarian, response, is, largely, ove...</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>The UN and humanitarian partners are scaling u...</td>\n",
       "      <td>(At, least, 3, million, people, affected, by, ...</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Syrian Arab Republic]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>The UN and humanitarian partners are scaling u...</td>\n",
       "      <td>(More, than, 4,500, deaths, and, more, than, 8...</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>4,500</td>\n",
       "      <td>None</td>\n",
       "      <td>[Syrian Arab Republic]</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>The UN and humanitarian partners are scaling u...</td>\n",
       "      <td>(The, districts, with, the, highest, number, o...</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Syrian Arab Republic]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_9</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>The UN and humanitarian partners are scaling u...</td>\n",
       "      <td>(As, of, 26, February, ,, more, than, 1,700, b...</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>rwdisastersumm_eq-2023-000015-tur_9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>The UN and humanitarian partners are scaling u...</td>\n",
       "      <td>(Some, 60, percent, of, partially, destroyed, ...</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Syrian Arab Republic]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                glide_id reference_auth_org  \\\n",
       "1746  EQ-2023-000015-TUR               OCHA   \n",
       "1747  EQ-2023-000015-TUR               OCHA   \n",
       "1748  EQ-2023-000015-TUR               OCHA   \n",
       "1749  EQ-2023-000015-TUR               OCHA   \n",
       "1750  EQ-2023-000015-TUR               OCHA   \n",
       "...                  ...                ...   \n",
       "1906  EQ-2023-000015-TUR               OCHA   \n",
       "1907  EQ-2023-000015-TUR               OCHA   \n",
       "1908  EQ-2023-000015-TUR               OCHA   \n",
       "1909  EQ-2023-000015-TUR               OCHA   \n",
       "1910  EQ-2023-000015-TUR               OCHA   \n",
       "\n",
       "                                  para_id  idx_para  idx_sent  \\\n",
       "1746  rwdisastersumm_eq-2023-000015-tur_0         0         0   \n",
       "1747  rwdisastersumm_eq-2023-000015-tur_0         0         1   \n",
       "1748  rwdisastersumm_eq-2023-000015-tur_0         0         2   \n",
       "1749  rwdisastersumm_eq-2023-000015-tur_0         0         3   \n",
       "1750  rwdisastersumm_eq-2023-000015-tur_0         0         4   \n",
       "...                                   ...       ...       ...   \n",
       "1906  rwdisastersumm_eq-2023-000015-tur_9         9         3   \n",
       "1907  rwdisastersumm_eq-2023-000015-tur_9         9         4   \n",
       "1908  rwdisastersumm_eq-2023-000015-tur_9         9         5   \n",
       "1909  rwdisastersumm_eq-2023-000015-tur_9         9         6   \n",
       "1910  rwdisastersumm_eq-2023-000015-tur_9         9         7   \n",
       "\n",
       "     source_level_country                               source_original_text  \\\n",
       "1746              Türkiye  On 6 February, a 7.7 magnitude earthquake stru...   \n",
       "1747              Türkiye  On 6 February, a 7.7 magnitude earthquake stru...   \n",
       "1748              Türkiye  On 6 February, a 7.7 magnitude earthquake stru...   \n",
       "1749              Türkiye  On 6 February, a 7.7 magnitude earthquake stru...   \n",
       "1750              Türkiye  On 6 February, a 7.7 magnitude earthquake stru...   \n",
       "...                   ...                                                ...   \n",
       "1906              Türkiye  The UN and humanitarian partners are scaling u...   \n",
       "1907              Türkiye  The UN and humanitarian partners are scaling u...   \n",
       "1908              Türkiye  The UN and humanitarian partners are scaling u...   \n",
       "1909              Türkiye  The UN and humanitarian partners are scaling u...   \n",
       "1910              Türkiye  The UN and humanitarian partners are scaling u...   \n",
       "\n",
       "                                    spacy_sent_no_paren reference_date_iso  \\\n",
       "1746  (On, 6, February, ,, a, 7.7, magnitude, earthq...         2023-02-06   \n",
       "1747  (This, is, Türkiye, 's, most, powerful, earthq...         2023-02-06   \n",
       "1748  (The, Government, of, Türkiye, has, since, iss...         2023-02-06   \n",
       "1749  (The, earthquake, also, heavily, impacted, nor...         2023-02-06   \n",
       "1750  (The, humanitarian, response, is, largely, ove...         2023-02-06   \n",
       "...                                                 ...                ...   \n",
       "1906  (At, least, 3, million, people, affected, by, ...         2023-02-28   \n",
       "1907  (More, than, 4,500, deaths, and, more, than, 8...         2023-02-28   \n",
       "1908  (The, districts, with, the, highest, number, o...         2023-02-28   \n",
       "1909  (As, of, 26, February, ,, more, than, 1,700, b...         2023-02-28   \n",
       "1910  (Some, 60, percent, of, partially, destroyed, ...         2023-02-28   \n",
       "\n",
       "     num_killed num_injured      identified_country  num_killed_int  \\\n",
       "1746       None        None                 Türkiye             NaN   \n",
       "1747       None        None                 Türkiye             NaN   \n",
       "1748       None        None                 Türkiye             NaN   \n",
       "1749       None        None  [Syrian Arab Republic]             NaN   \n",
       "1750       None        None                 Türkiye             NaN   \n",
       "...         ...         ...                     ...             ...   \n",
       "1906       None        None  [Syrian Arab Republic]             NaN   \n",
       "1907      4,500        None  [Syrian Arab Republic]          4500.0   \n",
       "1908       None        None  [Syrian Arab Republic]             NaN   \n",
       "1909       None        None                 Türkiye             NaN   \n",
       "1910       None        None  [Syrian Arab Republic]             NaN   \n",
       "\n",
       "      num_injured_int  \n",
       "1746              NaN  \n",
       "1747              NaN  \n",
       "1748              NaN  \n",
       "1749              NaN  \n",
       "1750              NaN  \n",
       "...               ...  \n",
       "1906              NaN  \n",
       "1907              NaN  \n",
       "1908              NaN  \n",
       "1909              NaN  \n",
       "1910              NaN  \n",
       "\n",
       "[165 rows x 14 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sents[df_sents['glide_id'] == 'EQ-2023-000015-TUR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "fd875e82-58c2-4c86-bc55-d3d839621074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    More than 4,500\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " deaths and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than 8,700\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " injuries due to the earthquakes have been reported in northwest \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Syria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COD_GPE</span>\n",
       "</mark>\n",
       ", as of \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    13 March\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", according to \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Health Cluster\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = \"\"\"More than 4,500 deaths and more than 8,700 injuries due to the earthquakes have been reported in northwest Syria, as of 13 March, according to the Health Cluster.\"\"\"\n",
    "doc = nlp(x)\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "397a3019-7021-484c-b834-f8f2eefc4476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>pcode_prefix</th>\n",
       "      <th>location_name</th>\n",
       "      <th>pcode</th>\n",
       "      <th>adm_lvl</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>location_normalized</th>\n",
       "      <th>lvl_pcode_len</th>\n",
       "      <th>split_pcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10184</th>\n",
       "      <td>Syrian Arab Republic</td>\n",
       "      <td>SY</td>\n",
       "      <td>Syria</td>\n",
       "      <td>SY</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>syria</td>\n",
       "      <td>2</td>\n",
       "      <td>SY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    country pcode_prefix location_name pcode  adm_lvl  \\\n",
       "10184  Syrian Arab Republic           SY         Syria    SY        0   \n",
       "\n",
       "      lang_code location_normalized  lvl_pcode_len split_pcode  \n",
       "10184        en               syria              2          SY  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_location[df_location['location_name'].str.lower() == 'syria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799a850-ba57-4c09-86be-faa4ac0cadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_pcode_from_location('Syria'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049253ac-08bd-4aaa-998d-83ad0dac7b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "        for e in entities:\n",
    "            pcode = \n",
    "            if (pcode is not None):\n",
    "                if (len(pcode) != 0):\n",
    "                    #print(pcode)\n",
    "                    admins.append(get_admin_chain(pcode)[adm_lvl])\n",
    "\n",
    "\n",
    "def get_pcode_from_location(loc, country_prefix='XX', lang_code='all'):\n",
    "\n",
    "    if country_prefix != 'XX': #if the country prefix is set, limit search to that\n",
    "        df_loc = df_location[df_location['pcode_prefix'] == country_prefix]\n",
    "    else:\n",
    "        df_loc = df_location\n",
    "\n",
    "    if lang_code != 'all': #secondary filter - especially important to remove dupes with diff langs share the same script\n",
    "        df_loc = df_loc[df_loc['lang_code'] == lang_code]\n",
    "        \n",
    "    matches = df_loc['pcode'][df_loc['location_name'].str.lower() == 'syria'.lower()].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
